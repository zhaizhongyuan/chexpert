{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using MASTER_PORT=45789\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import socket\n",
    "import os\n",
    "def find_free_port():\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.bind(('', 0))\n",
    "        return s.getsockname()[1]\n",
    "\n",
    "os.environ[\"MASTER_PORT\"] = str(find_free_port())\n",
    "print(f\"[INFO] Using MASTER_PORT={os.environ['MASTER_PORT']}\")\n",
    "from os.path import join, splitext\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix, roc_curve, auc\n",
    "from torchmetrics.classification import MultilabelAccuracy\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../../../../../../../storage/ice1/shared/bmed6780/mip_group_2/CheXpert Plus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheXpertDataset(Dataset):\n",
    "    def __init__(self, root_dir, patient_id_set, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Path to the parent directory containing subdirectories (e.g., 'label_folder').\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "            mode (str): Either \"train\" or \"valid\" to select the correct folder.\n",
    "        \"\"\"\n",
    "        \n",
    "        # self.label_folder = os.path.join(root_dir, 'chexbert_labels')\n",
    "        self.root = root_dir\n",
    "        self.img_path = os.path.join(self.root, 'PNG')\n",
    "        self.img_folders = [folder for folder in os.listdir(self.img_path) if splitext(folder)[1] == '']\n",
    "\n",
    "        self.label_folder = os.path.join(self.root, 'chexbert_labels')\n",
    "        self.label_path = os.path.join(self.label_folder, 'findings_fixed.json')\n",
    "        self.labels = []\n",
    "        self.img_paths = []\n",
    "        self.img_value_exception = 'train/patient32368/study1/view1_frontal.jpg'\n",
    "        self.transform = transform\n",
    "        \n",
    "        # load a dictionary of image paths and labels\n",
    "        with open(self.label_path, 'r') as f:\n",
    "            label_data = []\n",
    "            for line in f:\n",
    "                label_data.append(json.loads(line))\n",
    "\n",
    "        for label_dict in label_data:\n",
    "            label_list_per_sample = []\n",
    "            for key, value in label_dict.items():\n",
    "                if key == 'path_to_image': # save image paths\n",
    "                    split_values_list = splitext(value)[0].split('/')\n",
    "                    patient_id = int(split_values_list[1][7:])\n",
    "                    if value != self.img_value_exception and patient_id in patient_id_set:\n",
    "                        value = '/'.join(split_values_list) + '.png'\n",
    "                        for folder in self.img_folders:\n",
    "                            img_subfolder_path = os.path.join(os.path.join(self.img_path, folder), 'PNG')\n",
    "                            img_path = os.path.join(img_subfolder_path, value)\n",
    "                            if os.path.exists(img_path):\n",
    "                                self.img_paths.append(img_path)\n",
    "                    else:\n",
    "                        break # if img_path is not saved, neither will not its label be saved\n",
    "                else: # save label vectors\n",
    "                    if value is None: \n",
    "                        label_list_per_sample.append(0) # if this disease is not mentioned, it is perhaps not present\n",
    "                    elif value == -1:\n",
    "                        label_list_per_sample.append(0) # if radiologist is uncertain, chances of having this disease or being healthy are half half\n",
    "                    else:\n",
    "                        label_list_per_sample.append(value) # either having this disease or not\n",
    "            if len(label_list_per_sample) > 0: # empty list implies this sample is not from this set of patients\n",
    "                self.labels.append(torch.tensor(label_list_per_sample, dtype=torch.long))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # convert to RGB\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        img = img.to(torch.float32)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 10 17:22:02 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H200                    On  |   00000000:1A:00.0 Off |                    0 |\n",
      "| N/A   36C    P0             79W /  700W |       1MiB / 143771MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Available GPUs: {num_gpus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitDenseNetMultiLabel(pl.LightningModule):\n",
    "    def __init__(self, num_classes, lr=1e-3, weight_decay=1e-5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        weights = DenseNet121_Weights.DEFAULT\n",
    "        self.model = densenet121(weights=weights)\n",
    "        self.model.classifier = nn.Linear(self.model.classifier.in_features, num_classes)\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        self.train_acc = MultilabelAccuracy(num_labels=num_classes, threshold=0.5)\n",
    "        self.val_acc = MultilabelAccuracy(num_labels=num_classes, threshold=0.5)\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.val_preds = []\n",
    "        self.val_targets = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y.float())\n",
    "        preds = torch.sigmoid(logits)\n",
    "        acc = self.train_acc(preds, y.int())\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"train_acc\", acc, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y.float())\n",
    "        preds = torch.sigmoid(logits)\n",
    "        acc = self.val_acc(preds, y.int())\n",
    "\n",
    "        self.val_preds.append(preds.detach().cpu())\n",
    "        self.val_targets.append(y.detach().cpu())\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"val_acc\", acc, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        preds = torch.cat(self.val_preds)\n",
    "        targets = torch.cat(self.val_targets).int()\n",
    "\n",
    "        pred_labels = (preds > 0.5).int()\n",
    "\n",
    "        # log confusion matrix per class\n",
    "        cm = multilabel_confusion_matrix(targets, pred_labels)\n",
    "        for i in range(self.num_classes):\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.imshow(cm[i], interpolation='nearest', cmap=plt.cm.Blues)\n",
    "            ax.set_title(f\"Confusion Matrix - Class {i}\")\n",
    "            ax.set_xlabel(\"Predicted\")\n",
    "            ax.set_ylabel(\"True\")\n",
    "            wandb.log({f\"confusion_matrix_class_{i}\": wandb.Image(fig)})\n",
    "            plt.close(fig)\n",
    "\n",
    "        # log ROC curves\n",
    "        for i in range(self.num_classes):\n",
    "            fpr, tpr, _ = roc_curve(targets[:, i], preds[:, i])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
    "            ax.plot([0, 1], [0, 1], 'k--')\n",
    "            ax.set_title(f\"ROC Curve - Class {i}\")\n",
    "            ax.set_xlabel(\"False Positive Rate\")\n",
    "            ax.set_ylabel(\"True Positive Rate\")\n",
    "            ax.legend(loc=\"lower right\")\n",
    "            wandb.log({f\"roc_curve_class_{i}\": wandb.Image(fig)})\n",
    "            plt.close(fig)\n",
    "\n",
    "        # clear stored predictions\n",
    "        self.val_preds.clear()\n",
    "        self.val_targets.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir, batch_size=16, num_workers=4):\n",
    "        super().__init__()\n",
    "        self.root = data_dir\n",
    "        self.label_folder = os.path.join(self.root, 'chexbert_labels')\n",
    "        self.label_path = os.path.join(self.label_folder, 'findings_fixed.json')\n",
    "        self.train_patient_id_set = set()\n",
    "        self.test_patient_id_set = set()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.transform = DenseNet121_Weights.DEFAULT.transforms()\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # load a dictionary of image paths and labels\n",
    "        with open(self.label_path, 'r') as f:\n",
    "            label_data = []\n",
    "            for line in f:\n",
    "                label_data.append(json.loads(line))\n",
    "\n",
    "        for label_dict in label_data:\n",
    "            split_values_list = splitext(label_dict['path_to_image'])[0].split('/')\n",
    "            mode = split_values_list[0] # train or test\n",
    "            patient_id = int(split_values_list[1][7:])\n",
    "            if mode == 'train':\n",
    "                self.train_patient_id_set.add(patient_id)\n",
    "            elif mode == 'test':\n",
    "                self.test_patient_id_set.add(patient_id)\n",
    "        \n",
    "        train_patient_id_list = list(self.train_patient_id_set)\n",
    "        trainset_idx = np.random.choice(np.arange(len(train_patient_id_list)), int(0.75*len(train_patient_id_list)), replace=False)\n",
    "        train_patient_id_set = set([train_patient_id_list[idx] for idx in trainset_idx])\n",
    "        val_patient_id_set = self.train_patient_id_set - train_patient_id_set\n",
    "\n",
    "        self.train_set = CheXpertDataset(root_dir=self.root, patient_id_set=train_patient_id_set, transform=self.transform)\n",
    "        self.val_set = CheXpertDataset(root_dir=self.root, patient_id_set=val_patient_id_set, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size, num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzhaizhongyuan\u001b[0m (\u001b[33m11785-bhiksha\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for wandb.init()..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250410_172220-mqqhcvw6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/11785-bhiksha/chexpert_multilabel/runs/mqqhcvw6' target=\"_blank\">lr_1e-3_batch_size_16</a></strong> to <a href='https://wandb.ai/11785-bhiksha/chexpert_multilabel' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/11785-bhiksha/chexpert_multilabel' target=\"_blank\">https://wandb.ai/11785-bhiksha/chexpert_multilabel</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/11785-bhiksha/chexpert_multilabel/runs/mqqhcvw6' target=\"_blank\">https://wandb.ai/11785-bhiksha/chexpert_multilabel/runs/mqqhcvw6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/zzhai37/.conda/envs/nsp/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /storage/ice1/1/7/zzhai37/nsp/cheXpert/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model     | DenseNet           | 7.0 M  | train\n",
      "1 | loss_fn   | BCEWithLogitsLoss  | 0      | train\n",
      "2 | train_acc | MultilabelAccuracy | 0      | train\n",
      "3 | val_acc   | MultilabelAccuracy | 0      | train\n",
      "---------------------------------------------------------\n",
      "7.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.0 M     Total params\n",
      "27.873    Total estimated model params size (MB)\n",
      "436       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e77c62e13104e3db6dce8615686aeb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/zzhai37/.conda/envs/nsp/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:1188: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/hice1/zzhai37/.conda/envs/nsp/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:1188: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/hice1/zzhai37/.conda/envs/nsp/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:1188: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/hice1/zzhai37/.conda/envs/nsp/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:1188: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/hice1/zzhai37/.conda/envs/nsp/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:1188: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/hice1/zzhai37/.conda/envs/nsp/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:1188: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/hice1/zzhai37/.conda/envs/nsp/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:1188: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220c7575adcb490db7b36322c4d8c01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2eeda7c4aa44eefbe13959b7b25151f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81215a6b3f7248ab81bf9ede08c88050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3b99171f8c40ccb639bd56850fa436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82c46897fac4f5a94ec7f4dd0432bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b116eb430eb243b9bf9cb0151be35c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a4d17d119049b38a0f5ef2828b22b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29a54b879644b51a0c1c2aaec0b6d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33dc39e4b0694f688820ead3c0e45b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=8` reached.\n"
     ]
    }
   ],
   "source": [
    "model = LitDenseNetMultiLabel(num_classes=14)\n",
    "data = MultiLabelDataModule(data_dir=data_folder)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best-{epoch}-{val_loss:.2f}\",\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_top_k=1,\n",
    ")\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"chexpert_multilabel\", name=\"lr_1e-3_batch_size_16\")\n",
    "# wandb_logger = WandbLogger(project=\"chexpert_multilabel\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=8,\n",
    "    accelerator='gpu',\n",
    "    devices='auto',  # or specify a list like devices=[0,1]\n",
    "    # strategy='ddp',  # distributed data parallel\n",
    "    precision=\"16-mixed\",     # optional mixed precision\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
